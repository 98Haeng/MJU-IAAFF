{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cafaab",
   "metadata": {},
   "source": [
    "# 2. Keywords\n",
    "\n",
    "[수행 과정]\n",
    "- Abstract에 포함되는 키워드 찾아서 변환하기 (언더바 처리)\n",
    "- Keyword에 포함되는 것만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099aad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3fbaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "words_data = pd.read_csv('./Data/Preprocess_Data/Author_Keywords.csv')\n",
    "# abstract_data = pd.read_csv('./Data/Preprocess_Data/Abstract_preprocessing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebbafb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_data = abstract_data[['Year','Abstract2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478106cf",
   "metadata": {},
   "source": [
    "## 1. Abstract에 포함되는 키워드 찾아서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe4312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = words_data[words_data['count']>=20]\n",
    "# words_data.to_csv('Data/Preprocess_Data/up20_words.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d07fe77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abstract_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gx/q7vn3yv17rvb0vy6chbbbztw0000gn/T/ipykernel_720/3649199699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabstract_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'abstract_data' is not defined"
     ]
    }
   ],
   "source": [
    "abstract_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef0d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36032, 2267163)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_data), len(abstract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ac45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba7bec",
   "metadata": {},
   "source": [
    "### 완전일치한 부분이 있으면 공백에 _를 씌워서 바꿔주기\n",
    "- ex) neural network -> neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337d7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양쪽 공백 제거\n",
    "words_data['word'] = words_data['word'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e92931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_data에 공백을 언더바(_)로 대체\n",
    "words_data['word2'] = 0\n",
    "for i in range(len(words_data)):\n",
    "    if len(str(words_data['word'][i]).split(' ')) >1:\n",
    "        words_data['word2'][i] = words_data['word'][i].replace(' ','_')\n",
    "    else:\n",
    "        words_data['word2'][i] = words_data['word'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecf16433",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data['length'] = 0\n",
    "for i in range(len(words_data)):\n",
    "    words_data['length'][i] = len(str(words_data['word'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8668e03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>39529</td>\n",
       "      <td>machine_learning</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep learning</td>\n",
       "      <td>36992</td>\n",
       "      <td>deep_learning</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural network</td>\n",
       "      <td>18899</td>\n",
       "      <td>neural_network</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloud computing</td>\n",
       "      <td>17700</td>\n",
       "      <td>cloud_computing</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classification</td>\n",
       "      <td>17340</td>\n",
       "      <td>classification</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  count             word2  length\n",
       "0  machine learning  39529  machine_learning      16\n",
       "1     deep learning  36992     deep_learning      13\n",
       "2    neural network  18899    neural_network      14\n",
       "3   cloud computing  17700   cloud_computing      15\n",
       "4    classification  17340    classification      14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "words_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515fc1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h.5.1 [information interfaces and presentation...</td>\n",
       "      <td>44</td>\n",
       "      <td>h.5.1_[information_interfaces_and_presentation...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human centered computing human computer intera...</td>\n",
       "      <td>37</td>\n",
       "      <td>human_centered_computing_human_computer_intera...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i.3.7 [computer graphics]: three dimensional g...</td>\n",
       "      <td>29</td>\n",
       "      <td>i.3.7_[computer_graphics]:_three_dimensional_g...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i.3.6 [computer graphics]: methodology and tec...</td>\n",
       "      <td>30</td>\n",
       "      <td>i.3.6_[computer_graphics]:_methodology_and_tec...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h.5.2 [information interfaces and presentation...</td>\n",
       "      <td>20</td>\n",
       "      <td>h.5.2_[information_interfaces_and_presentation...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                word  count  \\\n",
       "0  h.5.1 [information interfaces and presentation...     44   \n",
       "1  human centered computing human computer intera...     37   \n",
       "2  i.3.7 [computer graphics]: three dimensional g...     29   \n",
       "3  i.3.6 [computer graphics]: methodology and tec...     30   \n",
       "4  h.5.2 [information interfaces and presentation...     20   \n",
       "\n",
       "                                               word2  length  \n",
       "0  h.5.1_[information_interfaces_and_presentation...     122  \n",
       "1  human_centered_computing_human_computer_intera...      89  \n",
       "2  i.3.7_[computer_graphics]:_three_dimensional_g...      81  \n",
       "3  i.3.6_[computer_graphics]:_methodology_and_tec...      75  \n",
       "4  h.5.2_[information_interfaces_and_presentation...      75  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length에 따라 정렬 (변환이 제대로 되지 않는 것 방지)\n",
    "words_data.sort_values(by='length', ascending=False, inplace=True)\n",
    "words_data.reset_index(drop=True, inplace=True)\n",
    "words_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc1128fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복되는 값 중 첫번째만 남기고 제거\n",
    "words_data.drop_duplicates(subset='word2', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb7bf55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35402"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d79f6a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [03:06<00:00, 53.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 디버깅\n",
    "# k = 251232\n",
    "abstract_data['Abstract3'] = \"\"\n",
    "words_dict = dict(zip(words_data2['word'], words_data2['word2']))\n",
    "\n",
    "for k in tqdm(range(10000)):\n",
    "    abstract = str(abstract_data['Abstract2'][k])\n",
    "    replaced_abstract = abstract\n",
    "\n",
    "    for word, word2 in words_dict.items():\n",
    "        replaced_abstract = replaced_abstract.replace(word, word2)\n",
    "\n",
    "    abstract_data['Abstract3'][k] = replaced_abstract\n",
    "    abstract_data['Abstract3'][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "276143d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [04:46<00:00, 34.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# 방법 1\n",
    "in_abstracts = []\n",
    "words_subset = set(words_data['word2'])  # 단어 집합을 집합(Set)으로 변환하여 탐색 시간을 단축\n",
    "\n",
    "# 정규식 패턴을 미리 생성하여 반복문 내에서 재사용\n",
    "pattern = re.compile(r'\\b({})\\b'.format('|'.join(map(re.escape, words_subset))))\n",
    "\n",
    "for k in tqdm(range(10000)):\n",
    "    abstract = abs_df['Abstract3'][k]\n",
    "    in_words = pattern.findall(abstract)\n",
    "    in_abstracts.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7b866879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 10000/10000 [00:00<00:00, 31486.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# 방법 2 (빈도수 고려 안하는 버전)\n",
    "in_abstracts2 = []\n",
    "words_subset = set(words_data['word2'])  # 단어 집합을 집합(Set)으로 변환하여 탐색 시간을 단축\n",
    "\n",
    "# 정규식 패턴을 미리 생성하여 반복문 내에서 재사용\n",
    "# pattern = re.compile(r'\\b({})\\b'.format('|'.join(map(re.escape, words_subset))))\n",
    "\n",
    "for k in tqdm(range(10000)):\n",
    "    abstract = set(abs_df['Abstract3'][k].split())\n",
    "    words_in_abstract = words_subset.intersection(abstract)\n",
    "    in_abstracts.append(list(words_in_abstract))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b617817e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'method',\n",
       " 'peer_to_peer_streaming',\n",
       " 'node',\n",
       " 'is',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'disk',\n",
       " 'user',\n",
       " 'content',\n",
       " 'be',\n",
       " 'a',\n",
       " 'malicious_user',\n",
       " 'content',\n",
       " 'method',\n",
       " 'ha',\n",
       " 'advantage',\n",
       " 'user',\n",
       " 's',\n",
       " 'disk',\n",
       " 'a',\n",
       " 'version',\n",
       " 'content',\n",
       " 'version',\n",
       " 'in',\n",
       " 'disk',\n",
       " 'can',\n",
       " 'be',\n",
       " 'in',\n",
       " 'it',\n",
       " 'is',\n",
       " 'content',\n",
       " 'distribution',\n",
       " 'it',\n",
       " 'ieee']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "57551ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_abstracts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d583878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 2267163/2267163 [13:21:24<00:00, 47.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# words 칼럼의 단어를 words2 칼럼의 단어로 대체\n",
    "abstract_data['Abstract3'] = \"\"\n",
    "\n",
    "words_dict = dict(zip(words_data2['word'], words_data2['word2']))\n",
    "\n",
    "for k in tqdm(range(len(abstract_data))):\n",
    "    abstract = str(abstract_data['Abstract2'][k])\n",
    "    replaced_abstract = abstract\n",
    "\n",
    "    for word, word2 in words_dict.items():\n",
    "        replaced_abstract = replaced_abstract.replace(word, word2)\n",
    "\n",
    "    abstract_data['Abstract3'][k] = replaced_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "47644d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_abstract = abstract_data[['Year','Abstract3']]\n",
    "new_abstract.to_csv('Data/Preprocess_Data/Abstract3.csv', encoding='utf-8-sig', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ad21ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a method for peer_to_peer_streaming of video_on_demand_with residential node is described a possible problem with doing peer_to_peer_video_on_demand_streaming is the necessity of storing on the disk of the residential user the content to be streamed allowing a malicious_user to distribute illegally the content the proposed method ha the advantage of storing on the user's disk only a reduced version of the content although the reduced version stored in disk can still be used in the proposed peer_to_peer_scheme it is not sufficient to recover the original content preventing an unauthorized distribution of it © 2013 ieee\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_abstract['Abstract3'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53d808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db069031",
   "metadata": {},
   "source": [
    "## --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a6f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df = pd.read_csv('./Data/Preprocess_Data/Abstract3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b703d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267158</th>\n",
       "      <td>2267158</td>\n",
       "      <td>2021</td>\n",
       "      <td>human_centered development of information_syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267159</th>\n",
       "      <td>2267159</td>\n",
       "      <td>2021</td>\n",
       "      <td>the computing device in cloud or fog data_cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267160</th>\n",
       "      <td>2267160</td>\n",
       "      <td>2021</td>\n",
       "      <td>mobile_technology are becoming more and more a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267161</th>\n",
       "      <td>2267161</td>\n",
       "      <td>2021</td>\n",
       "      <td>development of intelligent_system with the pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267162</th>\n",
       "      <td>2267162</td>\n",
       "      <td>2021</td>\n",
       "      <td>in this paper we gauge the utility of general ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Year                                          Abstract3\n",
       "0                 0  2013  a method for peer_to_peer_streaming of video_o...\n",
       "1                 1  2013  in this paper we discus the bacterial network_...\n",
       "2                 2  2013  this article treat a digital_humanity work in ...\n",
       "3                 3  2013  this work describes preliminary step towards n...\n",
       "4                 4  2013  goal extraction in learning_by_demonstration i...\n",
       "...             ...   ...                                                ...\n",
       "2267158     2267158  2021  human_centered development of information_syst...\n",
       "2267159     2267159  2021  the computing device in cloud or fog data_cent...\n",
       "2267160     2267160  2021  mobile_technology are becoming more and more a...\n",
       "2267161     2267161  2021  development of intelligent_system with the pur...\n",
       "2267162     2267162  2021  in this paper we gauge the utility of general ...\n",
       "\n",
       "[2267163 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e5a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a6cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 200000/200000 [1:49:15<00:00, 30.51it/s]\n"
     ]
    }
   ],
   "source": [
    "in_abstracts = []\n",
    "words_subset = set(words_data['word2'])  # 단어 집합을 집합(Set)으로 변환하여 탐색 시간을 단축\n",
    "\n",
    "# 정규식 패턴을 미리 생성하여 반복문 내에서 재사용\n",
    "pattern = re.compile(r'\\b({})\\b'.format('|'.join(map(re.escape, words_subset))))\n",
    "\n",
    "for k in tqdm(range(1300000,1500000))\n",
    "    abstract = abs_df['Abstract3'][k]\n",
    "    in_words = pattern.findall(abstract)\n",
    "    in_abstracts.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "035333e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in, paper, a, mathematical_model, is, distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in, paper, a, flow_network, backhaul, path_pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in, dna_strand_displacement, technology, ha, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development, internet_of_thing, ha, growth, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method, dna_strand_displacement, static, think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>in, paper, a, framework, classifying, change, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>present, outlier_removal, clustering_algorithm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>in, paper, problem, a, population, mobile_robo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>data_modeling, web_application, need, be, requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>in, paper, a, bayesian_approach, affine, auto_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     list\n",
       "0       in, paper, a, mathematical_model, is, distribu...\n",
       "1       in, paper, a, flow_network, backhaul, path_pla...\n",
       "2       in, dna_strand_displacement, technology, ha, a...\n",
       "3       development, internet_of_thing, ha, growth, po...\n",
       "4       method, dna_strand_displacement, static, think...\n",
       "...                                                   ...\n",
       "199995  in, paper, a, framework, classifying, change, ...\n",
       "199996  present, outlier_removal, clustering_algorithm...\n",
       "199997  in, paper, problem, a, population, mobile_robo...\n",
       "199998  data_modeling, web_application, need, be, requ...\n",
       "199999  in, paper, a, bayesian_approach, affine, auto_...\n",
       "\n",
       "[200000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df2 = pd.DataFrame(in_abstracts)\n",
    "# 각 행의 리스트를 공백으로 구분하여 연결\n",
    "abs_df2 = abs_df2.apply(lambda row: ', '.join(row.dropna().astype(str)), axis=1)\n",
    "# 이를 DataFrame으로 변환\n",
    "abs_df2 = pd.DataFrame(abs_df2, columns=['list'])\n",
    "abs_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1384016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abs_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe0e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df2.to_csv('Data/Preprocess_Data/추출본(1300000~1500000).csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b75ad351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 500000/500000 [4:08:16<00:00, 33.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(500000,1000000)):\n",
    "    abstract = abs_df['Abstract3'][k]\n",
    "    in_words = pattern.findall(abstract)\n",
    "    in_abstracts.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in tqdm(range(1000000,1600000)):\n",
    "#     abstract = abs_df['Abstract3'][k]\n",
    "#     in_words = pattern.findall(abstract)\n",
    "#     in_abstracts.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in tqdm(range(1600000,len(abs_df))):\n",
    "#     abstract = abs_df['Abstract3'][k]\n",
    "#     in_words = pattern.findall(abstract)\n",
    "#     in_abstracts.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02cb7f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 138848/138848 [1:10:10<00:00, 32.98it/s]\n"
     ]
    }
   ],
   "source": [
    "in_abstracts2 = []\n",
    "for k in tqdm(range(2128315,len(abs_df))):\n",
    "    abstract = abs_df['Abstract3'][k]\n",
    "    in_words = pattern.findall(abstract)\n",
    "    in_abstracts2.append([word for word in in_words if word in words_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e5c6dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>choice, effective, management, decision, city,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper, aim, at, debate, open_government, impac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vehicle_routing_problem_with_time_window, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>convergence, information_and_communication_tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper, control, approach, micro, satellite, au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138843</th>\n",
       "      <td>human_centered, development, information_syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138844</th>\n",
       "      <td>computing, device, in, cloud, or, fog, data_ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138845</th>\n",
       "      <td>mobile_technology, a, pedagogical_tool, in, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138846</th>\n",
       "      <td>development, intelligent_system, pursuit, dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138847</th>\n",
       "      <td>in, paper, utility, purpose, open, domain, sem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138848 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     list\n",
       "0       choice, effective, management, decision, city,...\n",
       "1       paper, aim, at, debate, open_government, impac...\n",
       "2       vehicle_routing_problem_with_time_window, is, ...\n",
       "3       convergence, information_and_communication_tec...\n",
       "4       paper, control, approach, micro, satellite, au...\n",
       "...                                                   ...\n",
       "138843  human_centered, development, information_syste...\n",
       "138844  computing, device, in, cloud, or, fog, data_ce...\n",
       "138845  mobile_technology, a, pedagogical_tool, in, hi...\n",
       "138846  development, intelligent_system, pursuit, dete...\n",
       "138847  in, paper, utility, purpose, open, domain, sem...\n",
       "\n",
       "[138848 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df2 = pd.DataFrame(in_abstracts2)\n",
    "# 각 행의 리스트를 공백으로 구분하여 연결\n",
    "abs_df2 = abs_df2.apply(lambda row: ', '.join(row.dropna().astype(str)), axis=1)\n",
    "# 이를 DataFrame으로 변환\n",
    "abs_df2 = pd.DataFrame(abs_df2, columns=['list'])\n",
    "abs_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a74cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df2.to_csv('Data/Preprocess_Data/추출본(2128315~).csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f1b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2b19c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(in_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03db7116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0, 2013, a method for peer_to_peer_streaming o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1, 2013, in this paper we discus the bacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2, 2013, this article treat a digital_humanity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3, 2013, this work describes preliminary step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4, 2013, goal extraction in learning_by_demons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267158</th>\n",
       "      <td>2267158, 2021, human_centered development of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267159</th>\n",
       "      <td>2267159, 2021, the computing device in cloud o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267160</th>\n",
       "      <td>2267160, 2021, mobile_technology are becoming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267161</th>\n",
       "      <td>2267161, 2021, development of intelligent_syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267162</th>\n",
       "      <td>2267162, 2021, in this paper we gauge the util...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267163 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      list\n",
       "0        0, 2013, a method for peer_to_peer_streaming o...\n",
       "1        1, 2013, in this paper we discus the bacterial...\n",
       "2        2, 2013, this article treat a digital_humanity...\n",
       "3        3, 2013, this work describes preliminary step ...\n",
       "4        4, 2013, goal extraction in learning_by_demons...\n",
       "...                                                    ...\n",
       "2267158  2267158, 2021, human_centered development of i...\n",
       "2267159  2267159, 2021, the computing device in cloud o...\n",
       "2267160  2267160, 2021, mobile_technology are becoming ...\n",
       "2267161  2267161, 2021, development of intelligent_syst...\n",
       "2267162  2267162, 2021, in this paper we gauge the util...\n",
       "\n",
       "[2267163 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df2 = pd.DataFrame(in_abstracts)\n",
    "# 각 행의 리스트를 공백으로 구분하여 연결\n",
    "abs_df2 = abs_df2.apply(lambda row: ', '.join(row.dropna().astype(str)), axis=1)\n",
    "# 이를 DataFrame으로 변환\n",
    "abs_df2 = pd.DataFrame(abs_df2, columns=['list'])\n",
    "abs_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3872cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df2.to_csv('Data/Preprocess_Data/추출본(~1000000).csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = abs_df2.copy()\n",
    "# 문자열 분할, 공백 제거 및 새로운 칼럼에 저장\n",
    "df2['list'] = df2['list'].apply(lambda x: x.split(',', 2)[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74418ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Data/Preprocess_Data/추출본.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76954840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b66dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./Data/Preprocess_Data/추출본.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3619d7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a method for peer_to_peer_streaming of video_on_demand_with residential node is described a possible problem with doing peer_to_peer_video_on_demand_streaming is the necessity of storing on the disk of the residential user the content to be streamed allowing a malicious_user to distribute illegally the content the proposed method ha the advantage of storing on the user's disk only a reduced version of the content although the reduced version stored in disk can still be used in the proposed peer_to_peer_scheme it is not sufficient to recover the original content preventing an unauthorized distribution of it © 2013 ieee\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e28fe101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1bc9060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0, 2013, a method for peer_to_peer_streaming o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1, 2013, in this paper we discus the bacterial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2, 2013, this article treat a digital_humanity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3, 2013, this work describes preliminary step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4, 2013, goal extraction in learning_by_demons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267158</th>\n",
       "      <td>2267158, 2021, human_centered development of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267159</th>\n",
       "      <td>2267159, 2021, the computing device in cloud o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267160</th>\n",
       "      <td>2267160, 2021, mobile_technology are becoming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267161</th>\n",
       "      <td>2267161, 2021, development of intelligent_syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267162</th>\n",
       "      <td>2267162, 2021, in this paper we gauge the util...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267163 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      list\n",
       "0        0, 2013, a method for peer_to_peer_streaming o...\n",
       "1        1, 2013, in this paper we discus the bacterial...\n",
       "2        2, 2013, this article treat a digital_humanity...\n",
       "3        3, 2013, this work describes preliminary step ...\n",
       "4        4, 2013, goal extraction in learning_by_demons...\n",
       "...                                                    ...\n",
       "2267158  2267158, 2021, human_centered development of i...\n",
       "2267159  2267159, 2021, the computing device in cloud o...\n",
       "2267160  2267160, 2021, mobile_technology are becoming ...\n",
       "2267161  2267161, 2021, development of intelligent_syst...\n",
       "2267162  2267162, 2021, in this paper we gauge the util...\n",
       "\n",
       "[2267163 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c95107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
