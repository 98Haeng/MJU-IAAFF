{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273861a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe72fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = pd.read_csv('./Data/Preprocess_Data/up20_words_완료.csv')\n",
    "abs_df = pd.read_csv('./Data/Preprocess_Data/Abstract3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653ab175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>제거</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>217</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>72</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>202</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>30</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>23</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  count 제거\n",
       "0    a    217  x\n",
       "1    b     72  x\n",
       "2    c    202  x\n",
       "3    d     30  x\n",
       "4    e     23  x"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b2a0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    25258\n",
       "Name: 제거, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data['제거'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57649031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year                                          Abstract3\n",
       "0           0  2013  a method for peer_to_peer_streaming of video_o...\n",
       "1           1  2013  in this paper we discus the bacterial network_...\n",
       "2           2  2013  this article treat a digital_humanity work in ...\n",
       "3           3  2013  this work describes preliminary step towards n...\n",
       "4           4  2013  goal extraction in learning_by_demonstration i..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56527aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = words_data[words_data['제거']!='x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c99370f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06ca0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data.drop('제거',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cfd0d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9187"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98391184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양쪽 공백 제거|\n",
    "words_data['word'] = words_data['word'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fc0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_data에 공백을 언더바(_)로 대체\n",
    "words_data['word2'] = 0\n",
    "for i in range(len(words_data)):\n",
    "    if len(str(words_data['word'][i]).split(' ')) >1:\n",
    "        words_data['word2'][i] = words_data['word'][i].replace(' ','_')\n",
    "    else:\n",
    "        words_data['word2'][i] = words_data['word'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a86674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data['length'] = 0\n",
    "for i in range(len(words_data)):\n",
    "    words_data['length'][i] = len(str(words_data['word'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e53f259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3dgis</td>\n",
       "      <td>21</td>\n",
       "      <td>3dgis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4isr</td>\n",
       "      <td>21</td>\n",
       "      <td>c4isr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacnet</td>\n",
       "      <td>21</td>\n",
       "      <td>bacnet</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hadith</td>\n",
       "      <td>21</td>\n",
       "      <td>hadith</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cog</td>\n",
       "      <td>22</td>\n",
       "      <td>cog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count   word2  length\n",
       "0   3dgis     21   3dgis       5\n",
       "1   c4isr     21   c4isr       5\n",
       "2  bacnet     21  bacnet       6\n",
       "3  hadith     21  hadith       6\n",
       "4     cog     22     cog       3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "words_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc513eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length에 따라 정렬 (변환이 제대로 되지 않는 것 방지)\n",
    "words_data.sort_values(by='length', ascending=False, inplace=True)\n",
    "words_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "898d06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복되는 값 중 첫번째만 남기고 제거\n",
    "words_data.drop_duplicates(subset='word2', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f67a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = abs_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "181fd7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year                                          Abstract3\n",
       "0           0  2013  a method for peer_to_peer_streaming of video_o...\n",
       "1           1  2013  in this paper we discus the bacterial network_...\n",
       "2           2  2013  this article treat a digital_humanity work in ...\n",
       "3           3  2013  this work describes preliminary step towards n...\n",
       "4           4  2013  goal extraction in learning_by_demonstration i..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ee0448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 칼럼의 뒤의 두 자리 추출\n",
    "t['year_suffix'] = t['Year'].astype(str).str[-2:]\n",
    "# list 칼럼의 단어들을 분리하여 리스트로 변환\n",
    "word_lists = t['Abstract3'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927375e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [a, method, for, peer_to_peer_streaming, of, v...\n",
       "1          [in, this, paper, we, discus, the, bacterial, ...\n",
       "2          [this, article, treat, a, digital_humanity, wo...\n",
       "3          [this, work, describes, preliminary, step, tow...\n",
       "4          [goal, extraction, in, learning_by_demonstrati...\n",
       "                                 ...                        \n",
       "2267158    [human_centered, development, of, information_...\n",
       "2267159    [the, computing, device, in, cloud, or, fog, d...\n",
       "2267160    [mobile_technology, are, becoming, more, and, ...\n",
       "2267161    [development, of, intelligent_system, with, th...\n",
       "2267162    [in, this, paper, we, gauge, the, utility, of,...\n",
       "Name: Abstract3, Length: 2267163, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f4c0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2283535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합을 집합(Set)으로 변환하여 탐색 시간을 단축\n",
    "words_subset = set(words_data['word2'])\n",
    "\n",
    "# 정규식 패턴을 미리 생성하여 반복문 내에서 재사용\n",
    "pattern = re.compile(r'\\b({})\\b'.format('|'.join(map(re.escape, words_subset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c70bf936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe9fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d49b5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 212.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# 단어가 해당되면 연도까지 붙여주기\n",
    "new_word_lists = []  # 매칭된 단어에 suffix가 추가된 리스트\n",
    "\n",
    "for words, suffix in tqdm(zip(word_lists, t2['year_suffix']), total=len(t2)):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if pattern.match(word):\n",
    "            word = str(suffix) + '_' + word\n",
    "\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    new_word_lists.append(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d272560",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_strings = [' '.join(word_list) for word_list in new_word_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4de4a352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'given a connected undirected_graph whose edge are labelled the minimum labelling spanning_tree problem seek a spanning_tree whose edge have the smallest number of distinct label in recent work the mlst problem ha been shown to be np_hard and some effective heuristic have been proposed and analysed in this paper we present preliminary result of a currently on going project regarding the implementation of an intelligent_optimization_algorithm to solve the mlst problem this algorithm is obtained by the basic variable_neighbourhood_search_heuristic with the integration of other 13_complement from 13_machine_learning statistic and experimental_algorithmics in order to produce high quality performance and to completely automate the resulting optimization_strategy © 2013 springer verlag'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_strings[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc035edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2['reAbs'] = new_word_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53d11588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>year_suffix</th>\n",
       "      <th>reAbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "      <td>13</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "      <td>13</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "      <td>13</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "      <td>13</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "      <td>13</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>2013</td>\n",
       "      <td>identification of cancer associated protein is...</td>\n",
       "      <td>13</td>\n",
       "      <td>identification of 13_cancer associated protein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>2013</td>\n",
       "      <td>a new on_chip ca5nb2tio12 dielectric_resonator...</td>\n",
       "      <td>13</td>\n",
       "      <td>a new on_chip ca5nb2tio12 13_dielectric_resona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2013</td>\n",
       "      <td>building account for roughly 40% of all u ener...</td>\n",
       "      <td>13</td>\n",
       "      <td>13_building account for roughly 40% of all u e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>2013</td>\n",
       "      <td>this paper present a simple interval type 2 fu...</td>\n",
       "      <td>13</td>\n",
       "      <td>this paper present a simple interval type 2 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2013</td>\n",
       "      <td>a relevant issue in the annotation of digital_...</td>\n",
       "      <td>13</td>\n",
       "      <td>a relevant issue in the 13_annotation of digit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Year                                          Abstract3  \\\n",
       "0            0  2013  a method for peer_to_peer_streaming of video_o...   \n",
       "1            1  2013  in this paper we discus the bacterial network_...   \n",
       "2            2  2013  this article treat a digital_humanity work in ...   \n",
       "3            3  2013  this work describes preliminary step towards n...   \n",
       "4            4  2013  goal extraction in learning_by_demonstration i...   \n",
       "..         ...   ...                                                ...   \n",
       "95          95  2013  identification of cancer associated protein is...   \n",
       "96          96  2013  a new on_chip ca5nb2tio12 dielectric_resonator...   \n",
       "97          97  2013  building account for roughly 40% of all u ener...   \n",
       "98          98  2013  this paper present a simple interval type 2 fu...   \n",
       "99          99  2013  a relevant issue in the annotation of digital_...   \n",
       "\n",
       "   year_suffix                                              reAbs  \n",
       "0           13  a method for peer_to_peer_streaming of video_o...  \n",
       "1           13  in this paper we discus the bacterial network_...  \n",
       "2           13  this article treat a digital_humanity work in ...  \n",
       "3           13  this work describes preliminary step towards n...  \n",
       "4           13  goal extraction in learning_by_demonstration i...  \n",
       "..         ...                                                ...  \n",
       "95          13  identification of 13_cancer associated protein...  \n",
       "96          13  a new on_chip ca5nb2tio12 13_dielectric_resona...  \n",
       "97          13  13_building account for roughly 40% of all u e...  \n",
       "98          13  this paper present a simple interval type 2 13...  \n",
       "99          13  a relevant issue in the 13_annotation of digit...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b13f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871fb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2417b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7730a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식을 사용하여 's와 영어 알파벳, 숫자, 그리고 underscore('_') 이외의 문자 제거\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].astype(str)\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9_\\s]|'s\\b\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77525c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백이 2칸 이상이면 한칸으로 줄어듦\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].apply(lambda x: re.sub(r'\\s{2,}', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e518f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25ff6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                               | 0/1000000 [01:34<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [01:53<00:00, 2640.44it/s]\n",
      "\n",
      " 10%|███▍                              | 30637/300000 [00:11<01:47, 2507.62it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [01:52<00:00, 2670.62it/s]\u001b[A\n",
      "\n",
      " 16%|█████▍                            | 47909/300000 [00:19<01:52, 2239.83it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [02:04<00:00, 2413.04it/s]\u001b[A\n",
      "\n",
      " 13%|████▎                             | 38267/300000 [00:15<01:35, 2727.69it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [02:13<00:00, 2248.63it/s]\u001b[A\n",
      "\n",
      " 13%|████▎                             | 38061/300000 [00:14<01:55, 2276.83it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [01:55<00:00, 2592.52it/s]\u001b[A\n",
      "\n",
      "  3%|█                                  | 8621/300000 [00:28<01:50, 2629.42it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [02:16<00:00, 2190.99it/s]\u001b[A\n",
      "\n",
      " 10%|███▍                              | 29969/300000 [00:11<01:45, 2570.87it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 300000/300000 [02:30<00:00, 1994.67it/s]\u001b[A\n",
      "\n",
      " 24%|████████                          | 39467/167163 [00:15<00:43, 2945.56it/s]\u001b[A\n",
      "100%|█████████████████████████████████| 167163/167163 [01:05<00:00, 2543.45it/s]\u001b[A\n",
      "\n",
      "2400000it [15:54, 2513.37it/s]                                                  \u001b[A\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].astype(str)\n",
    "\n",
    "# 불용어 설정\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tokens 칼럼 : 불용어 제거 추가버전\n",
    "chunk_size = 300000  # 처리할 청크 크기 설정\n",
    "\n",
    "# 청크별로 데이터 처리\n",
    "total_rows = len(abs_df)\n",
    "start = 0\n",
    "end = chunk_size\n",
    "\n",
    "pbar = tqdm(total=total_rows)  # 진행 상황 표시를 위한 tqdm 객체 생성\n",
    "\n",
    "while start < total_rows:\n",
    "    chunk_data = abs_df['Abstract3'].iloc[start:end]\n",
    "    abs_df.loc[start:end, 'tokens'] = chunk_data.progress_apply(lambda x: [word for word in word_tokenize(x) if word not in stop_words])\n",
    "\n",
    "    start += chunk_size\n",
    "    end += chunk_size\n",
    "    if end > total_rows:\n",
    "        end = total_rows\n",
    "\n",
    "    pbar.update(chunk_size)  # tqdm 객체 업데이트\n",
    "\n",
    "pbar.close()  # tqdm 객체 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b8b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df.to_csv('원본불용어제거.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c00fc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['method',\n",
       " 'peer_to_peer_streaming',\n",
       " 'video_on_demand',\n",
       " 'residential',\n",
       " 'node',\n",
       " 'described',\n",
       " 'possible',\n",
       " 'problem',\n",
       " 'peer_to_peer',\n",
       " 'video_on_demand',\n",
       " 'streaming',\n",
       " 'necessity',\n",
       " 'storing',\n",
       " 'disk',\n",
       " 'residential',\n",
       " 'user',\n",
       " 'content',\n",
       " 'streamed',\n",
       " 'allowing',\n",
       " 'malicious_user',\n",
       " 'distribute',\n",
       " 'illegally',\n",
       " 'content',\n",
       " 'proposed',\n",
       " 'method',\n",
       " 'ha',\n",
       " 'advantage',\n",
       " 'storing',\n",
       " 'users',\n",
       " 'disk',\n",
       " 'reduced',\n",
       " 'version',\n",
       " 'content',\n",
       " 'although',\n",
       " 'reduced',\n",
       " 'version',\n",
       " 'stored',\n",
       " 'disk',\n",
       " 'still',\n",
       " 'used',\n",
       " 'proposed',\n",
       " 'peer_to_peer',\n",
       " 'scheme',\n",
       " 'sufficient',\n",
       " 'recover',\n",
       " 'original',\n",
       " 'content',\n",
       " 'preventing',\n",
       " 'unauthorized',\n",
       " 'distribution',\n",
       " '2013',\n",
       " 'ieee']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba97c124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a method for peer_to_peer_streaming of video_on_demand with residential node is described a possible problem with doing peer_to_peer video_on_demand streaming is the necessity of storing on the disk of the residential user the content to be streamed allowing a malicious_user to distribute illegally the content the proposed method ha the advantage of storing on the users disk only a reduced version of the content although the reduced version stored in disk can still be used in the proposed peer_to_peer scheme it is not sufficient to recover the original content preventing an unauthorized distribution of it 2013 ieee'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df['Abstract3'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64651d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df['tokens'] = abs_df['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76955d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41ed1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "      <td>method peer_to_peer_streaming video_on_demand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "      <td>paper discus bacterial network_communication_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "      <td>article treat digital_humanity work classical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "      <td>work describes preliminary step towards nano s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "      <td>goal extraction learning_by_demonstration comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year                                          Abstract3  \\\n",
       "0           0  2013  a method for peer_to_peer_streaming of video_o...   \n",
       "1           1  2013  in this paper we discus the bacterial network_...   \n",
       "2           2  2013  this article treat a digital_humanity work in ...   \n",
       "3           3  2013  this work describes preliminary step towards n...   \n",
       "4           4  2013  goal extraction in learning_by_demonstration i...   \n",
       "\n",
       "                                              tokens  \n",
       "0  method peer_to_peer_streaming video_on_demand ...  \n",
       "1  paper discus bacterial network_communication_d...  \n",
       "2  article treat digital_humanity work classical ...  \n",
       "3  work describes preliminary step towards nano s...  \n",
       "4  goal extraction learning_by_demonstration comp...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df = pd.read_csv('원본불용어제거.csv')\n",
    "abs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9458378",
   "metadata": {},
   "source": [
    "2. 'modelling'을 'modeling'으로 수정\n",
    "3. 'ada boost'를 'adaboost'로 수정\n",
    "4. 'zig bee'를 'zigbee'로 수정\n",
    "5. 'alzheimer’s disease'를 'alzheimer disease'로 수정\n",
    "6. 'optimisation'을 'optimization'으로 수정\n",
    "7. 'neural networks'를 'neural network'으로\n",
    "8. 'audiovisual'을 'audio visual'로\n",
    "9. 'authorisation'을 'authorization'로\n",
    "10. 'chatbots'를 'chatbot'로\n",
    "11. 'conceptualisation'을 'conceptualization'로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed51013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 2267163/2267163 [00:13<00:00, 169149.55it/s]\n"
     ]
    }
   ],
   "source": [
    "replacement_dict = {\n",
    "    'ada_boost': 'adaboost',\n",
    "    'zig_bee': 'zigbee',\n",
    "    'optimisation': 'optimization',\n",
    "    'neural_networks': 'neural_network',\n",
    "    'audiovisual': 'audio_visual',\n",
    "    'authorisation': 'authorization',\n",
    "    'chatbots': 'chatbot',\n",
    "    'conceptualisation': 'conceptualization'\n",
    "}\n",
    "\n",
    "def replace_words(text):\n",
    "    for old_word, new_word in replacement_dict.items():\n",
    "        text = text.replace(old_word, new_word)\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()  # tqdm을 사용하기 위해 pandas에 연결\n",
    "\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].progress_apply(replace_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4146e77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29057</th>\n",
       "      <td>29057</td>\n",
       "      <td>2011</td>\n",
       "      <td>prediction of nuclear protein is one of the ma...</td>\n",
       "      <td>prediction nuclear protein one major challenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71440</th>\n",
       "      <td>71440</td>\n",
       "      <td>2020</td>\n",
       "      <td>a module for assessing the investment risk of ...</td>\n",
       "      <td>module assessing investment risk virtual compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84086</th>\n",
       "      <td>84086</td>\n",
       "      <td>2008</td>\n",
       "      <td>promoter recognition ha been attempted using d...</td>\n",
       "      <td>promoter recognition ha attempted using differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106850</th>\n",
       "      <td>106850</td>\n",
       "      <td>2008</td>\n",
       "      <td>in this paper chromatic information is integra...</td>\n",
       "      <td>paper chromatic information integrated ada_boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115092</th>\n",
       "      <td>115092</td>\n",
       "      <td>2015</td>\n",
       "      <td>in this paper a moving vehicle_detection_algor...</td>\n",
       "      <td>paper moving vehicle_detection_algorithm based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226517</th>\n",
       "      <td>2226517</td>\n",
       "      <td>2019</td>\n",
       "      <td>people are careful when they are trying to buy...</td>\n",
       "      <td>people careful trying buy new house budget mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257305</th>\n",
       "      <td>2257305</td>\n",
       "      <td>2021</td>\n",
       "      <td>in recent year due to the exponential increase...</td>\n",
       "      <td>recent year due exponential increase usage mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259924</th>\n",
       "      <td>2259924</td>\n",
       "      <td>2021</td>\n",
       "      <td>in this paper we describe our submission for t...</td>\n",
       "      <td>paper describe submission hasoc 2021 contest t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262452</th>\n",
       "      <td>2262452</td>\n",
       "      <td>2021</td>\n",
       "      <td>computer_aided_diagnosis_system have become a ...</td>\n",
       "      <td>computer_aided_diagnosis_system become signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265028</th>\n",
       "      <td>2265028</td>\n",
       "      <td>2021</td>\n",
       "      <td>in this paper we describe our submission for p...</td>\n",
       "      <td>paper describe submission pan clef 2021 contes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Year                                          Abstract3  \\\n",
       "29057         29057  2011  prediction of nuclear protein is one of the ma...   \n",
       "71440         71440  2020  a module for assessing the investment risk of ...   \n",
       "84086         84086  2008  promoter recognition ha been attempted using d...   \n",
       "106850       106850  2008  in this paper chromatic information is integra...   \n",
       "115092       115092  2015  in this paper a moving vehicle_detection_algor...   \n",
       "...             ...   ...                                                ...   \n",
       "2226517     2226517  2019  people are careful when they are trying to buy...   \n",
       "2257305     2257305  2021  in recent year due to the exponential increase...   \n",
       "2259924     2259924  2021  in this paper we describe our submission for t...   \n",
       "2262452     2262452  2021  computer_aided_diagnosis_system have become a ...   \n",
       "2265028     2265028  2021  in this paper we describe our submission for p...   \n",
       "\n",
       "                                                    tokens  \n",
       "29057    prediction nuclear protein one major challenge...  \n",
       "71440    module assessing investment risk virtual compa...  \n",
       "84086    promoter recognition ha attempted using differ...  \n",
       "106850   paper chromatic information integrated ada_boo...  \n",
       "115092   paper moving vehicle_detection_algorithm based...  \n",
       "...                                                    ...  \n",
       "2226517  people careful trying buy new house budget mar...  \n",
       "2257305  recent year due exponential increase usage mul...  \n",
       "2259924  paper describe submission hasoc 2021 contest t...  \n",
       "2262452  computer_aided_diagnosis_system become signifi...  \n",
       "2265028  paper describe submission pan clef 2021 contes...  \n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df['Abstract3'] = abs_df['Abstract3'].str.replace('ada_boost', 'adaboost', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42b85d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Year, Abstract3, tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df[abs_df['Abstract3'].str.contains('ada_boost', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b6df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f66bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5821a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c3316ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "      <td>method peer_to_peer_streaming video_on_demand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "      <td>paper discus bacterial network_communication_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "      <td>article treat digital_humanity work classical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "      <td>work describes preliminary step towards nano s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "      <td>goal extraction learning_by_demonstration comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267158</th>\n",
       "      <td>2267158</td>\n",
       "      <td>2021</td>\n",
       "      <td>human_centered development of information_syst...</td>\n",
       "      <td>human_centered development information_system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267159</th>\n",
       "      <td>2267159</td>\n",
       "      <td>2021</td>\n",
       "      <td>the computing device in cloud or fog data_cent...</td>\n",
       "      <td>computing device cloud fog data_center remain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267160</th>\n",
       "      <td>2267160</td>\n",
       "      <td>2021</td>\n",
       "      <td>mobile_technology are becoming more and more a...</td>\n",
       "      <td>mobile_technology becoming accepted used pedag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267161</th>\n",
       "      <td>2267161</td>\n",
       "      <td>2021</td>\n",
       "      <td>development of intelligent_system with the pur...</td>\n",
       "      <td>development intelligent_system pursuit detecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267162</th>\n",
       "      <td>2267162</td>\n",
       "      <td>2021</td>\n",
       "      <td>in this paper we gauge the utility of general ...</td>\n",
       "      <td>paper gauge utility general purpose open domai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2228239 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Year                                          Abstract3  \\\n",
       "0                 0  2013  a method for peer_to_peer_streaming of video_o...   \n",
       "1                 1  2013  in this paper we discus the bacterial network_...   \n",
       "2                 2  2013  this article treat a digital_humanity work in ...   \n",
       "3                 3  2013  this work describes preliminary step towards n...   \n",
       "4                 4  2013  goal extraction in learning_by_demonstration i...   \n",
       "...             ...   ...                                                ...   \n",
       "2267158     2267158  2021  human_centered development of information_syst...   \n",
       "2267159     2267159  2021  the computing device in cloud or fog data_cent...   \n",
       "2267160     2267160  2021  mobile_technology are becoming more and more a...   \n",
       "2267161     2267161  2021  development of intelligent_system with the pur...   \n",
       "2267162     2267162  2021  in this paper we gauge the utility of general ...   \n",
       "\n",
       "                                                    tokens  \n",
       "0        method peer_to_peer_streaming video_on_demand ...  \n",
       "1        paper discus bacterial network_communication_d...  \n",
       "2        article treat digital_humanity work classical ...  \n",
       "3        work describes preliminary step towards nano s...  \n",
       "4        goal extraction learning_by_demonstration comp...  \n",
       "...                                                    ...  \n",
       "2267158  human_centered development information_system ...  \n",
       "2267159  computing device cloud fog data_center remain ...  \n",
       "2267160  mobile_technology becoming accepted used pedag...  \n",
       "2267161  development intelligent_system pursuit detecti...  \n",
       "2267162  paper gauge utility general purpose open domai...  \n",
       "\n",
       "[2228239 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df[abs_df['Year']>=1994]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309859c",
   "metadata": {},
   "source": [
    "--- 7/10 여기까지 진행했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12114f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract3</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>a method for peer_to_peer_streaming of video_o...</td>\n",
       "      <td>method peer_to_peer_streaming video_on_demand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>in this paper we discus the bacterial network_...</td>\n",
       "      <td>paper discus bacterial network_communication_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>this article treat a digital_humanity work in ...</td>\n",
       "      <td>article treat digital_humanity work classical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>this work describes preliminary step towards n...</td>\n",
       "      <td>work describes preliminary step towards nano s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>goal extraction in learning_by_demonstration i...</td>\n",
       "      <td>goal extraction learning_by_demonstration comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year                                          Abstract3  \\\n",
       "0           0  2013  a method for peer_to_peer_streaming of video_o...   \n",
       "1           1  2013  in this paper we discus the bacterial network_...   \n",
       "2           2  2013  this article treat a digital_humanity work in ...   \n",
       "3           3  2013  this work describes preliminary step towards n...   \n",
       "4           4  2013  goal extraction in learning_by_demonstration i...   \n",
       "\n",
       "                                              tokens  \n",
       "0  method peer_to_peer_streaming video_on_demand ...  \n",
       "1  paper discus bacterial network_communication_d...  \n",
       "2  article treat digital_humanity work classical ...  \n",
       "3  work describes preliminary step towards nano s...  \n",
       "4  goal extraction learning_by_demonstration comp...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df = pd.read_csv('원본불용어제거.csv')\n",
    "abs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a533a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = abs_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 칼럼의 뒤의 두 자리 추출\n",
    "t['year_suffix'] = t['year'].astype(str).str[-2:]\n",
    "# list 칼럼의 단어들을 분리하여 리스트로 변환\n",
    "word_lists = t['tokens'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ac98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합을 집합(Set)으로 변환하여 탐색 시간을 단축\n",
    "words_subset = set(words_data['word2'])\n",
    "\n",
    "# 정규식 패턴을 미리 생성하여 반복문 내에서 재사용\n",
    "pattern = re.compile(r'\\b({})\\b'.format('|'.join(map(re.escape, words_subset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_lists = []  # 매칭된 단어에 suffix가 추가된 리스트\n",
    "\n",
    "for words, suffix in tqdm(zip(word_lists, t2['year_suffix']), total=len(t)):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if pattern.match(word):\n",
    "            new_words.append(str(suffix) + '_' + word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    new_word_lists.append(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8129f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7dd5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950123c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "abs_df['Abstract3'] = abs_df['Abstract3'].astype(str)\n",
    "\n",
    "# 불용어 설정\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tokens 칼럼 : 불용어 제거 추가버전\n",
    "abs_df['tokens'] = abs_df['Abstract3'].apply(lambda x: [word for word in tqdm(word_tokenize(x), desc='Processing', unit='word') if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae95cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba403a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
